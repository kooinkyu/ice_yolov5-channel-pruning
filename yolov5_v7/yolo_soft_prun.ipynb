{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e316b5ff-6fc1-4589-a90f-38378b8fe3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting numpy<2.3.0,>=2 (from opencv-python)\n",
      "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, opencv-python\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.15.1 requires numpy<2.0.0,>=1.23.5, but you have numpy 2.2.6 which is incompatible.\n",
      "numba 0.59.1 requires numpy<1.27,>=1.22, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.2.6 opencv-python-4.12.0.88\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fb24efe-484e-43a5-b015-623a7ba511b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting numpy<2\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "!pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4b94474-04e6-47b8-83fd-127961bbfdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch-pruning==2.0.1= (from versions: 0.1.0, 0.1.1, 0.1.2, 0.1.3, 0.1.4, 0.1.5, 0.2.0, 0.2.1, 0.2.4, 0.2.5, 0.2.6, 0.2.7, 0.2.8, 1.0.0, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.1.4, 1.1.5, 1.1.6, 1.1.7, 1.1.8, 1.1.9, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.2.4, 1.2.5, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.3.4, 1.3.5, 1.3.6, 1.3.7, 1.4.0, 1.4.1, 1.4.2, 1.4.3, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 1.6.0, 1.6.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch-pruning==2.0.1=\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torch-pruning==2.0.1="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ccb909-a1c0-48ae-b5f6-c91c0b519f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch-pruning in /opt/conda/lib/python3.11/site-packages (1.6.1)\n",
      "Collecting thop\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: torch>=2.0 in /opt/conda/lib/python3.11/site-packages (from torch-pruning) (2.2.2+cu121)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torch-pruning) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (1.12.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (2024.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->torch-pruning) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0->torch-pruning) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0->torch-pruning) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=2.0->torch-pruning) (1.3.0)\n",
      "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: thop\n",
      "Successfully installed thop-0.1.1.post2209072238\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch-pruning thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4be79809-9e0a-4873-a934-364df85c3f81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch-pruning\n",
      "Version: 1.6.1\n",
      "Summary: Towards Any Structural Pruning\n",
      "Home-page: https://github.com/VainF/Torch-Pruning\n",
      "Author: Gongfan Fang\n",
      "Author-email: gongfan@u.nus.edu\n",
      "License: \n",
      "Location: /opt/conda/lib/python3.11/site-packages\n",
      "Requires: numpy, torch\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show torch_pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54adb169-3135-41e3-b96f-44731815f989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/lost+found/ice_sleep_detpj/yolov5_v7\n"
     ]
    }
   ],
   "source": [
    "cd lost+found/ice_sleep_detpj/yolov5_v7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805014c7-5e31-4428-b7f3-2889737ae921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTRIBUTING.md       \u001b[0m\u001b[01;34mdata\u001b[0m/                    setup.cfg\n",
      "LICENSE               detect.py                train.py\n",
      "README.md             detect_after_pruning.py  train_prune_iter.py\n",
      "Untitled.ipynb        export.py                tutorial.ipynb\n",
      "Untitled1.ipynb       hubconf.py               \u001b[01;34mutils\u001b[0m/\n",
      "\u001b[01;34m__pycache__\u001b[0m/          \u001b[01;34mlost+found\u001b[0m/              val.py\n",
      "\u001b[01;34manalysis\u001b[0m/             \u001b[01;34mmodels\u001b[0m/                  yolo_soft_prun.ipynb\n",
      "benchmarks.py         requirements.txt         yolov5n.pt\n",
      "best_pruned_state.pt  \u001b[01;34mruns\u001b[0m/                    yolov5s.pt\n",
      "\u001b[01;34mclassify\u001b[0m/             \u001b[01;34msegment\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bef5993-9368-4344-807b-426d916710d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model pruned to 0.299 global sparsity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Soft Pruning ÏôÑÎ£å ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/prune/pruned_0.3.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils.torch_utils import prune\n",
    "model_path = '/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/ice_eye_mouth20_pruned_finetune_33_40/weights/best.pt'\n",
    "pruned_save = '/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/prune/pruned_0.3.pt'\n",
    "\n",
    "ckpt = torch.load(model_path, map_location='cpu')\n",
    "model = ckpt['model'].float()\n",
    "prune(model, 0.3)  # Í∞ÄÏ§ëÏπò 30% Ìù¨ÏÜåÌôî\n",
    "torch.save({'model': model}, pruned_save)\n",
    "print(f\"‚úÖ Soft Pruning ÏôÑÎ£å ‚Üí {pruned_save}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fcb91a3-2dd0-4a42-b8c4-f23e8fff2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, csv, json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# === Í≤ΩÎ°ú (ÎÑ§ ÌôòÍ≤ΩÏóê ÎßûÏ∂∞ Îëî Í∏∞Î≥∏Í∞í) ===\n",
    "REPO = \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7\"\n",
    "WEIGHTS_BASE = f\"{REPO}/runs/train/ice_eye_mouth20_pruned_finetune_33_40/weights/best.pt\"    # ÌîÑÎ£®Îãù Ï†Ñ(ÌïôÏäµ ÏôÑÎ£å) Í∞ÄÏ§ëÏπò\n",
    "WEIGHTS_SOFT = f\"{REPO}/runs/prune/pruned_0.3.pt\"                                            # soft pruning ÌõÑ Í∞ÄÏ§ëÏπò(Ìù¨ÏÜåÌôî)\n",
    "OUT_DIR = f\"{REPO}/runs/prune/analysis\"  # Í≤∞Í≥º Ï†ÄÏû• Ìè¥Îçî\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Î°úÎìú Ïú†Ìã∏\n",
    "def load_yolov5_model(ckpt_path):\n",
    "    ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "    model = ckpt['model'].float().eval()\n",
    "    return model\n",
    "\n",
    "model_base = load_yolov5_model(WEIGHTS_BASE)\n",
    "model_soft = load_yolov5_model(WEIGHTS_SOFT)  # ÏóÜÏúºÎ©¥ Ïù¥ Ï§ÑÎßå Ï£ºÏÑù Ï≤òÎ¶¨ÌïòÍ≥† 'soft ÏóÜÏùå' Î™®ÎìúÎ°ú ÏßÑÌñâ Í∞ÄÎä•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfc9e13b-e4ba-4bd9-9d0e-0f028bfa8eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Î†àÏù¥Ïñ¥Î≥Ñ ÌÜµÍ≥Ñ/Ìù¨ÏÜåÎèÑ Ï†ÄÏû• ÏôÑÎ£å\n",
      "   ‚Ä¢ base sparsity: 0.0000\n",
      "   ‚Ä¢ soft sparsity: 0.2990\n"
     ]
    }
   ],
   "source": [
    "def iter_conv_bn_modules(model):\n",
    "    \"\"\"\n",
    "    YOLOv5Ïùò Conv Î∏îÎ°ù(ÎåÄÎ∂ÄÎ∂Ñ models.common.Conv)Ïóê ÎåÄÌï¥\n",
    "    - conv: nn.Conv2d\n",
    "    - bn: nn.BatchNorm2d\n",
    "    Î•º ÏïàÏ†ÑÌïòÍ≤å Ï∞æÏïÑÏÑú yield\n",
    "    \"\"\"\n",
    "    for name, m in model.named_modules():\n",
    "        conv = getattr(m, 'conv', None)\n",
    "        bn   = getattr(m, 'bn', None)\n",
    "        if isinstance(conv, nn.Conv2d) and isinstance(bn, nn.BatchNorm2d):\n",
    "            yield name, m, conv, bn\n",
    "\n",
    "def layer_stats(model):\n",
    "    stats = []\n",
    "    global_bn_gamma = []\n",
    "    for name, m, conv, bn in iter_conv_bn_modules(model):\n",
    "        # BN gamma\n",
    "        gamma = bn.weight.detach().cpu().numpy()\n",
    "        gamma_abs = np.abs(gamma)\n",
    "        global_bn_gamma.extend(gamma_abs.tolist())\n",
    "\n",
    "        # Conv weight L1 (per output channel)\n",
    "        w = conv.weight.detach().cpu().numpy()  # [out_c, in_c, k, k]\n",
    "        oc, ic, kh, kw = w.shape\n",
    "        w_l1 = np.abs(w).reshape(oc, -1).sum(axis=1)  # out-channel Î≥Ñ L1\n",
    "        # sparsity(0 ÎπÑÏú®): Conv Í∞ÄÏ§ëÏπò Í∏∞Ï§Ä\n",
    "        zero_ratio = float((w == 0).sum()) / float(w.size)\n",
    "\n",
    "        stats.append({\n",
    "            'layer': name,\n",
    "            'out_channels': int(oc),\n",
    "            'in_channels': int(ic),\n",
    "            'kernel': f'{kh}x{kw}',\n",
    "            'bn_gamma_mean': float(gamma_abs.mean()),\n",
    "            'bn_gamma_min':  float(gamma_abs.min()),\n",
    "            'bn_gamma_max':  float(gamma_abs.max()),\n",
    "            'conv_l1_mean':  float(w_l1.mean()),\n",
    "            'conv_l1_min':   float(w_l1.min()),\n",
    "            'conv_l1_max':   float(w_l1.max()),\n",
    "            'conv_zero_ratio': zero_ratio,\n",
    "        })\n",
    "    return pd.DataFrame(stats), np.array(global_bn_gamma)\n",
    "\n",
    "def global_weight_sparsity(model):\n",
    "    total = 0\n",
    "    zero  = 0\n",
    "    for p in model.parameters():\n",
    "        if p is None: \n",
    "            continue\n",
    "        arr = p.detach().cpu().numpy()\n",
    "        total += arr.size\n",
    "        zero  += (arr == 0).sum()\n",
    "    return zero / max(1, total)\n",
    "\n",
    "# === ÌîÑÎ£®Îãù Ï†Ñ/ÌõÑ(soft) ÌÜµÍ≥Ñ\n",
    "df_base, gamma_base = layer_stats(model_base)\n",
    "sparsity_base = global_weight_sparsity(model_base)\n",
    "\n",
    "try:\n",
    "    df_soft, gamma_soft = layer_stats(model_soft)\n",
    "    sparsity_soft = global_weight_sparsity(model_soft)\n",
    "    has_soft = True\n",
    "except Exception:\n",
    "    print(\"‚ö†Ô∏è soft pruning Î™®Îç∏ÏùÑ Î°úÎìúÌïòÏßÄ Î™ªÌï¥, ÌîÑÎ£®Îãù Ï†ÑÎßå Î∂ÑÏÑùÌï©ÎãàÎã§.\")\n",
    "    has_soft = False\n",
    "\n",
    "# Ï†ÄÏû•\n",
    "df_base.to_csv(f\"{OUT_DIR}/layer_stats_base.csv\", index=False)\n",
    "if has_soft:\n",
    "    df_soft.to_csv(f\"{OUT_DIR}/layer_stats_soft.csv\", index=False)\n",
    "\n",
    "with open(f\"{OUT_DIR}/global_sparsity.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"base\": float(sparsity_base),\n",
    "        \"soft\": float(sparsity_soft) if has_soft else None\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Î†àÏù¥Ïñ¥Î≥Ñ ÌÜµÍ≥Ñ/Ìù¨ÏÜåÎèÑ Ï†ÄÏû• ÏôÑÎ£å\")\n",
    "print(f\"   ‚Ä¢ base sparsity: {sparsity_base:.4f}\")\n",
    "if has_soft:\n",
    "    print(f\"   ‚Ä¢ soft sparsity: {sparsity_soft:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5053d9c1-d93c-4074-86a4-97e63a7df822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before mean: 1.0096096637820409\n",
      "After mean : 1.0096096637820409\n",
      "Before min : 0.29638671875\n",
      "After min  : 0.29638671875\n",
      "Before max : 1.9423828125\n",
      "After max  : 1.9423828125\n"
     ]
    }
   ],
   "source": [
    "print(\"Before mean:\", np.mean(gamma_base))\n",
    "print(\"After mean :\", np.mean(gamma_soft))\n",
    "print(\"Before min :\", np.min(gamma_base))\n",
    "print(\"After min  :\", np.min(gamma_soft))\n",
    "print(\"Before max :\", np.max(gamma_base))\n",
    "print(\"After max  :\", np.max(gamma_soft))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b1ec7f7-ee7b-47c6-845d-15c8eb1effa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÏãúÍ∞ÅÌôî ÏôÑÎ£å Î∞è Ï†ÄÏû•Îê®:\n",
      "   ‚Ä¢ /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/prune/analysis/bn_gamma_hist.png\n",
      "   ‚Ä¢ /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/prune/analysis/bn_gamma_cdf.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "## BN ÏãúÍ∞ÅÌôî\n",
    "# ======== Í≤ΩÎ°ú ÏÑ§Ï†ï ========\n",
    "OUT_DIR = \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/prune/analysis\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ======== ÏòàÏãú Î≥ÄÏàò (Ïù¥ÎØ∏ Ï°¥Ïû¨ÌïúÎã§Í≥† Í∞ÄÏ†ï) ========\n",
    "# gamma_base = ...\n",
    "# gamma_soft = ...\n",
    "# has_soft = True\n",
    "\n",
    "# ======== 1Ô∏è‚É£ BN |Œ≥| Î∂ÑÌè¨ (ÌûàÏä§ÌÜ†Í∑∏Îû® + KDE) ========\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# ÌûàÏä§ÌÜ†Í∑∏Îû®\n",
    "plt.hist(gamma_base, bins=60, alpha=0.45, label='Before (BN |Œ≥|)',\n",
    "         color='royalblue', density=True, edgecolor='black', linewidth=0.3)\n",
    "if has_soft:\n",
    "    plt.hist(gamma_soft, bins=60, alpha=0.45, label='After Soft (BN |Œ≥|)',\n",
    "             color='orange', density=True, edgecolor='black', linewidth=0.3)\n",
    "\n",
    "# KDE (ÏÑ†Ìòï Î∂ÑÌè¨ Í≥°ÏÑ†)\n",
    "sns.kdeplot(gamma_base, color='royalblue', linewidth=1.8)\n",
    "if has_soft:\n",
    "    sns.kdeplot(gamma_soft, color='orange', linewidth=1.8)\n",
    "\n",
    "plt.xlabel('|BN gamma|', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.title('BN Scale (|Œ≥|) Distribution', fontsize=14, weight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUT_DIR}/bn_gamma_hist.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# ======== 2Ô∏è‚É£ CDF (ÎàÑÏ†Å Î∂ÑÌè¨) ========\n",
    "def cdf(arr):\n",
    "    a = np.sort(np.abs(arr))\n",
    "    y = np.arange(1, len(a)+1) / len(a)\n",
    "    return a, y\n",
    "\n",
    "x_b, y_b = cdf(gamma_base)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x_b, y_b, label='Before (CDF)', color='royalblue', linewidth=2)\n",
    "if has_soft:\n",
    "    x_s, y_s = cdf(gamma_soft)\n",
    "    plt.plot(x_s, y_s, label='After Soft (CDF)', color='orange', linewidth=2)\n",
    "\n",
    "plt.xlabel('|BN gamma| (sorted)', fontsize=12)\n",
    "plt.ylabel('Cumulative ratio', fontsize=12)\n",
    "plt.title('BN Scale CDF (Channel Importance Accumulation)', fontsize=14, weight='bold')\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.legend(fontsize=10)\n",
    "plt.xlim([0.2, 1.8])   # BN Ïä§ÏºÄÏùº Íµ¨Í∞Ñ Ï°∞Ï†ï\n",
    "plt.ylim([0, 1.02])\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUT_DIR}/bn_gamma_cdf.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"‚úÖ ÏãúÍ∞ÅÌôî ÏôÑÎ£å Î∞è Ï†ÄÏû•Îê®:\")\n",
    "print(f\"   ‚Ä¢ {OUT_DIR}/bn_gamma_hist.png\")\n",
    "print(f\"   ‚Ä¢ {OUT_DIR}/bn_gamma_cdf.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c06fc25-0db9-4c10-af64-23efc21fbb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.0.conv                              out=  32  in=   3\n",
      "model.1.conv                              out=  56  in=  32\n",
      "model.2.cv1.conv                          out=  28  in=  56\n",
      "model.2.cv2.conv                          out=  28  in=  56\n",
      "model.2.cv3.conv                          out=  56  in=  56\n",
      "model.2.m.0.cv1.conv                      out=  28  in=  28\n",
      "model.2.m.0.cv2.conv                      out=  28  in=  28\n",
      "model.3.conv                              out= 104  in=  56\n",
      "model.4.cv1.conv                          out=  52  in= 104\n",
      "model.4.cv2.conv                          out=  52  in= 104\n",
      "model.4.cv3.conv                          out= 104  in= 104\n",
      "model.4.m.0.cv1.conv                      out=  52  in=  52\n",
      "model.4.m.0.cv2.conv                      out=  52  in=  52\n",
      "model.4.m.1.cv1.conv                      out=  52  in=  52\n",
      "model.4.m.1.cv2.conv                      out=  52  in=  52\n",
      "model.5.conv                              out= 208  in= 104\n",
      "model.6.cv1.conv                          out= 104  in= 208\n",
      "model.6.cv2.conv                          out= 104  in= 208\n",
      "model.6.cv3.conv                          out= 208  in= 208\n",
      "model.6.m.0.cv1.conv                      out= 104  in= 104\n",
      "model.6.m.0.cv2.conv                      out= 104  in= 104\n",
      "model.6.m.1.cv1.conv                      out= 104  in= 104\n",
      "model.6.m.1.cv2.conv                      out= 104  in= 104\n",
      "model.6.m.2.cv1.conv                      out= 104  in= 104\n",
      "model.6.m.2.cv2.conv                      out= 104  in= 104\n",
      "model.7.conv                              out= 416  in= 208\n",
      "model.8.cv1.conv                          out= 208  in= 416\n",
      "model.8.cv2.conv                          out= 208  in= 416\n",
      "model.8.cv3.conv                          out= 416  in= 416\n",
      "model.8.m.0.cv1.conv                      out= 208  in= 208\n",
      "model.8.m.0.cv2.conv                      out= 208  in= 208\n",
      "model.9.cv1.conv                          out= 208  in= 416\n",
      "model.9.cv2.conv                          out= 416  in= 832\n",
      "model.10.conv                             out= 208  in= 416\n",
      "model.13.cv1.conv                         out= 104  in= 416\n",
      "model.13.cv2.conv                         out= 104  in= 416\n",
      "model.13.cv3.conv                         out= 208  in= 208\n",
      "model.13.m.0.cv1.conv                     out= 104  in= 104\n",
      "model.13.m.0.cv2.conv                     out= 104  in= 104\n",
      "model.14.conv                             out= 104  in= 208\n",
      "model.17.cv1.conv                         out=  52  in= 208\n",
      "model.17.cv2.conv                         out=  52  in= 208\n",
      "model.17.cv3.conv                         out= 104  in= 104\n",
      "model.17.m.0.cv1.conv                     out=  52  in=  52\n",
      "model.17.m.0.cv2.conv                     out=  52  in=  52\n",
      "model.18.conv                             out= 104  in= 104\n",
      "model.20.cv1.conv                         out= 104  in= 208\n",
      "model.20.cv2.conv                         out= 104  in= 208\n",
      "model.20.cv3.conv                         out= 208  in= 208\n",
      "model.20.m.0.cv1.conv                     out= 104  in= 104\n",
      "model.20.m.0.cv2.conv                     out= 104  in= 104\n",
      "model.21.conv                             out= 208  in= 208\n",
      "model.23.cv1.conv                         out= 208  in= 416\n",
      "model.23.cv2.conv                         out= 208  in= 416\n",
      "model.23.cv3.conv                         out= 416  in= 416\n",
      "model.23.m.0.cv1.conv                     out= 208  in= 208\n",
      "model.23.m.0.cv2.conv                     out= 208  in= 208\n",
      "model.24.m.0                              out=  33  in= 104\n",
      "model.24.m.1                              out=  33  in= 208\n",
      "model.24.m.2                              out=  33  in= 416\n",
      "\n",
      "‚úÖ Ï¥ù 56Í∞úÏùò Conv2d Î†àÏù¥Ïñ¥Í∞Ä ÌîÑÎ£®Îãù ÎåÄÏÉÅÏûÖÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "from models.yolo import Model\n",
    "import torch, torch.nn as nn\n",
    "\n",
    "ckpt = torch.load(WEIGHTS_BASE, map_location=DEVICE)\n",
    "model = ckpt[\"model\"] if \"model\" in ckpt else ckpt\n",
    "model = model.float().to(DEVICE).eval()\n",
    "\n",
    "prunable_modules = []\n",
    "for name, m in model.named_modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(f\"{name:40s}  out={m.out_channels:4d}  in={m.in_channels:4d}\")\n",
    "        if m.out_channels >= 32:\n",
    "            prunable_modules.append(m)\n",
    "print(f\"\\n‚úÖ Ï¥ù {len(prunable_modules)}Í∞úÏùò Conv2d Î†àÏù¥Ïñ¥Í∞Ä ÌîÑÎ£®Îãù ÎåÄÏÉÅÏûÖÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a9a244e-2bba-41b9-9cc6-7a2a4078b3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded model from: /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/ice_eye_mouth20_softBN_finetune_1e-3_fixed/weights/best.pt\n",
      "[BEFORE] FLOPs(G): 5.559, Params(M): 4.663\n",
      "üîç Found 57 Conv layers potentially prunable\n",
      "\n",
      "=== üîé [Debug] Prunable Modules ===\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BasePruner' object has no attribute 'groups'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 118\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Ïã§Ìñâ\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[43mprune_yolov5_debug\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWEIGHTS_BASE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSAVE_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[32], line 91\u001b[0m, in \u001b[0;36mprune_yolov5_debug\u001b[0;34m(weights, save_path, imgsz, device)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# ‚úÖ Ïñ¥Îñ§ Î™®ÎìàÎì§Ïù¥ Ïã§Ï†ú pruning ÎåÄÏÉÅÏù∏ÏßÄ ÌôïÏù∏\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== üîé [Debug] Prunable Modules ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpruner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dep \u001b[38;5;129;01min\u001b[39;00m group\u001b[38;5;241m.\u001b[39mdep_set:\n\u001b[1;32m     93\u001b[0m         m \u001b[38;5;241m=\u001b[39m dep\u001b[38;5;241m.\u001b[39mtarget\u001b[38;5;241m.\u001b[39mmodule\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BasePruner' object has no attribute 'groups'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "YOLOv5 Safe Channel Pruning (torch-pruning v2 Debug)\n",
    "- Ïã§Ï†ú pruningÏù¥ 0%Ïùº Îïå ÏõêÏù∏ Ï∂îÏ†ÅÏö©\n",
    "\"\"\"\n",
    "\n",
    "import os, torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import torch_pruning as tp\n",
    "from models.yolo import Detect\n",
    "import models.common as common\n",
    "\n",
    "# ============================================================\n",
    "# ÌôòÍ≤Ω ÏÑ§Ï†ï\n",
    "# ============================================================\n",
    "REPO = \"/home/jovyan/lost+found/ice_sleep_detpj\"\n",
    "WEIGHTS_BASE = f\"{REPO}/yolov5_v7/runs/train/ice_eye_mouth20_softBN_finetune_1e-3_fixed/weights/best.pt\"\n",
    "SAVE_PATH    = f\"{REPO}/yolov5_v7/runs/prune/ice_eye_mouth20_debugv2.pt\"\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMG_SIZE = 640\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Ìï®Ïàò Ï†ïÏùò\n",
    "# ============================================================\n",
    "def load_model(weights, device=DEVICE):\n",
    "    ckpt = torch.load(weights, map_location=device)\n",
    "    model = ckpt[\"model\"] if \"model\" in ckpt else ckpt\n",
    "    model = model.float().to(device)\n",
    "    print(f\"‚úÖ Loaded model from: {weights}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def count_ops_params(model, imgsz=640, device=DEVICE):\n",
    "    dummy = torch.randn(1, 3, imgsz, imgsz, device=device)\n",
    "    flops, params = tp.utils.count_ops_and_params(model, dummy)\n",
    "    return flops, params\n",
    "\n",
    "\n",
    "def collect_ignored_layers(model):\n",
    "    ignored = []\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, Detect):\n",
    "            ignored.append(m)\n",
    "            for mi in getattr(m, \"m\", []):\n",
    "                ignored.append(mi)\n",
    "    return ignored\n",
    "\n",
    "\n",
    "def collect_prunable_convs(model):\n",
    "    prunable = []\n",
    "    for name, m in model.named_modules():\n",
    "        if isinstance(m, common.Conv):\n",
    "            out_ch = m.conv.out_channels\n",
    "            if out_ch >= 8:  # ÎÑàÎ¨¥ ÏûëÏùÄ Í±¥ Ï†úÏô∏\n",
    "                prunable.append((name, m))\n",
    "    return prunable\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ÌîÑÎ£®Îãù Ìï®Ïàò\n",
    "# ============================================================\n",
    "def prune_yolov5_debug(weights, save_path, imgsz=640, device=DEVICE):\n",
    "    model = load_model(weights, device)\n",
    "    base_flops, base_params = count_ops_params(model, imgsz, device)\n",
    "    print(f\"[BEFORE] FLOPs(G): {base_flops/1e9:.3f}, Params(M): {base_params/1e6:.3f}\")\n",
    "\n",
    "    example_inputs = torch.randn(1, 3, imgsz, imgsz, device=device)\n",
    "    model.train()  # ‚úÖ autograd trace ÌïÑÏöî (evalÏù¥Î©¥ ÏûëÎèôÏïàÌï®)\n",
    "\n",
    "    ignored_layers = collect_ignored_layers(model)\n",
    "    prunable_layers = collect_prunable_convs(model)\n",
    "    print(f\"üîç Found {len(prunable_layers)} Conv layers potentially prunable\")\n",
    "\n",
    "    importance = tp.importance.MagnitudeImportance(p=1)\n",
    "\n",
    "    pruner = tp.pruner.MagnitudePruner(\n",
    "        model=model,\n",
    "        example_inputs=example_inputs,\n",
    "        importance=importance,\n",
    "        global_pruning=True,\n",
    "        ch_sparsity=0.3,  # Í∏∞Î≥∏ 30%\n",
    "        ignored_layers=ignored_layers,\n",
    "        round_to=8,\n",
    "    )\n",
    "\n",
    "    # ‚úÖ Ïñ¥Îñ§ Î™®ÎìàÎì§Ïù¥ Ïã§Ï†ú pruning ÎåÄÏÉÅÏù∏ÏßÄ ÌôïÏù∏\n",
    "    print(\"\\n=== üîé [Debug] Prunable Modules ===\")\n",
    "    for group in pruner.groups:\n",
    "        for dep in group.dep_set:\n",
    "            m = dep.target.module\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                print(f\" - {dep.target.name:40s} | out_ch={m.out_channels}\")\n",
    "    print(\"=============================\\n\")\n",
    "\n",
    "    # ‚úÖ pruning ÏàòÌñâ\n",
    "    pruner.step()\n",
    "\n",
    "    # Í≤∞Í≥º ÎπÑÍµê\n",
    "    pruned_flops, pruned_params = count_ops_params(model, imgsz, device)\n",
    "    print(f\"[AFTER ] FLOPs(G): {pruned_flops/1e9:.3f}, Params(M): {pruned_params/1e6:.3f}\")\n",
    "    print(f\"[DIFF  ] FLOPs ‚Üì {(base_flops - pruned_flops)/base_flops * 100:.2f}%, \"\n",
    "          f\"Params ‚Üì {(base_params - pruned_params)/base_params * 100:.2f}%\")\n",
    "\n",
    "    # ‚úÖ Ï†ÄÏû•\n",
    "    os.makedirs(Path(save_path).parent, exist_ok=True)\n",
    "    torch.save({\"model\": model}, save_path)\n",
    "    print(f\"‚úÖ Saved debug model to: {save_path}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Ïã§Ìñâ\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\" or True:\n",
    "    prune_yolov5_debug(WEIGHTS_BASE, SAVE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "548e40ba-ef37-4d8e-ac2b-d618686eacac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/jovyan/lost+found/ice_sleep_detpj/data/ice_driver_ct.yaml, weights=['/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/prune/pruned_0.3.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=ice_pruned_eval, exist_ok=True, half=False, dnn=False\n",
      "YOLOv5 üöÄ v7.0-0-g915bbf29 Python-3.11.9 torch-2.2.2+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12010MiB)\n",
      "\n",
      "Fusing layers... \n",
      "my_YOLOv5s_prune summary: 157 layers, 4655291 parameters, 0 gradients, 11.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jovyan/lost+found/ice_sleep_detpj/data/YOLO_dataset/labels/v\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   Exception in thread Thread-3 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 305, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 91, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "Exception in thread Thread-4 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 305, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 91, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "Exception in thread Thread-5 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 305, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 91, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "Exception in thread Thread-6 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 305, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 91, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "                 Class     Images  Instances          P          R      mAP50   Exception in thread Thread-7 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 305, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 91, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "Exception in thread Thread-8 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 305, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 91, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141       0.96      0.965      0.982       0.66\n",
      "             Leye_Open      38704      29887       0.98      0.987      0.993      0.724\n",
      "           Leye_Closed      38704       8067       0.94      0.953      0.971      0.572\n",
      "             Reye_Open      38704      28901      0.976      0.974      0.992      0.701\n",
      "           Reye_Closed      38704       7237      0.929      0.937      0.964      0.558\n",
      "            Mouth_Open      38704       8308      0.959      0.955      0.987      0.703\n",
      "          Mouth_Closed      38704      21741      0.976      0.986      0.988        0.7\n",
      "Speed: 0.1ms pre-process, 0.8ms inference, 0.3ms NMS per image at shape (16, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/ice_pruned_eval\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python val.py \\\n",
    "  --weights /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/prune/pruned_0.3.pt \\\n",
    "  --data /home/jovyan/lost+found/ice_sleep_detpj/data/ice_driver_ct.yaml \\\n",
    "  --img 640 --batch-size 16 \\\n",
    "  --name ice_pruned_eval --exist-ok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed663c31-e334-4087-bd5e-dfa9b1ef0d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-30 23:57:17.978607: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-30 23:57:17.997860: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-10-30 23:57:17.997887: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-10-30 23:57:17.998378: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-30 23:57:18.001420: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-30 23:57:18.370443: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/ice_eye_mouth20_pruned_finetune_33_40/weights/best.pt, cfg=/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/models/my_yolov5s_prune.yaml, data=/home/jovyan/lost+found/ice_sleep_detpj/data/ice_driver_ct.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train, name=ice_eye_mouth20_softBN_finetune_1e-3_fixed, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 444 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v7.0-0-g915bbf29 Python-3.11.9 torch-2.2.2+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12010MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     16240  models.common.Conv                      [32, 56, 3, 2]                \n",
      "  2                -1  1     14448  models.common.C3                        [56, 56, 1]                   \n",
      "  3                -1  1     52624  models.common.Conv                      [56, 104, 3, 2]               \n",
      "  4                -1  2     76544  models.common.C3                        [104, 104, 2]                 \n",
      "  5                -1  1    195104  models.common.Conv                      [104, 208, 3, 2]              \n",
      "  6                -1  3    413088  models.common.C3                        [208, 208, 3]                 \n",
      "  7                -1  1    779584  models.common.Conv                      [208, 416, 3, 2]              \n",
      "  8                -1  1    781248  models.common.C3                        [416, 416, 1]                 \n",
      "  9                -1  1    433888  models.common.SPPF                      [416, 416, 5]                 \n",
      " 10                -1  1     86944  models.common.Conv                      [416, 208, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    239200  models.common.C3                        [416, 208, 1, False]          \n",
      " 14                -1  1     21840  models.common.Conv                      [208, 104, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     60112  models.common.C3                        [208, 104, 1, False]          \n",
      " 18                -1  1     97552  models.common.Conv                      [104, 104, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    195936  models.common.C3                        [208, 208, 1, False]          \n",
      " 21                -1  1    389792  models.common.Conv                      [208, 208, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1    781248  models.common.C3                        [416, 416, 1, False]          \n",
      " 24      [17, 20, 23]  1     24123  models.yolo.Detect                      [6, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [104, 208, 416]]\n",
      "my_YOLOv5s_prune summary: 214 layers, 4663035 parameters, 4663035 gradients, 11.2 GFLOPs\n",
      "\n",
      "Transferred 348/349 items from /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/ice_eye_mouth20_pruned_finetune_33_40/weights/best.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/jovyan/lost+found/ice_sleep_detpj/data/YOLO_dataset/labels\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/jovyan/lost+found/ice_sleep_detpj/data/YOLO_dataset/images/train/R_540_40_M_15_M0_G1_C0_11.jpg: ignoring corrupt image/label: negative label values [   -0.92917]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jovyan/lost+found/ice_sleep_detpj/data/YOLO_dataset/labels/v\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.80 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/ice_eye_mouth20_softBN_finetune_1e-3_fixed/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/ice_eye_mouth20_softBN_finetune_1e-3_fixed\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/29      2.99G     0.0189   0.009225   0.004232         78        640:  Exception in thread Thread-5 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 305, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 91, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "       0/29      3.03G    0.02083   0.008327   0.002363         68        640:  Exception in thread Thread-6 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 305, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 91, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "       0/29      3.03G    0.02052   0.008114    0.00366         62        640:  Exception in thread Thread-7 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 305, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 91, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "       0/29      3.05G    0.02133   0.009288   0.001936         20        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.963      0.961      0.983      0.669\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/29      3.05G    0.02363   0.009932   0.002435         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.962      0.961      0.983      0.667\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/29      3.05G    0.02327    0.01058   0.003418         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.961      0.962      0.983      0.666\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/29      3.05G    0.02297    0.01085   0.003814          6        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.958      0.961      0.982      0.661\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/29      3.05G    0.02397    0.01117   0.004175          8        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.937       0.87      0.928      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/29      3.05G    0.02462    0.01142   0.004411          9        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.907      0.468       0.71      0.424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/29      3.05G    0.02439    0.01139   0.004293         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.343      0.635       0.54      0.308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/29      3.05G     0.0241    0.01129   0.004165          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.505      0.443      0.456      0.254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/29      3.05G    0.02377    0.01123   0.004052          9        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.614      0.285      0.418       0.23\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/29      3.05G    0.02355    0.01115   0.003954         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.636      0.169      0.379      0.207\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/29      3.05G    0.02333     0.0111   0.003836          3        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.659     0.0901       0.36      0.199\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/29      3.05G    0.02319    0.01104   0.003829         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.653     0.0592      0.346       0.19\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/29      3.05G    0.02298    0.01096   0.003718         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.652     0.0508      0.343      0.186\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/29      3.05G    0.02276    0.01093   0.003691         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141       0.65     0.0681      0.349      0.195\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/29      3.05G    0.02264    0.01086   0.003626          8        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.661      0.109      0.371      0.204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/29      3.05G    0.02246    0.01083   0.003582          4        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.656      0.187      0.401      0.222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/29      3.05G     0.0223    0.01074    0.00347         11        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141       0.61      0.319      0.444      0.246\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/29      3.05G    0.02209    0.01068   0.003449         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141        0.5      0.473      0.493      0.279\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/29      3.05G     0.0219    0.01066   0.003369         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.351      0.625      0.557      0.322\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/29      3.05G    0.02172    0.01058   0.003314         12        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.947       0.39       0.65      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/29      3.05G    0.02156    0.01052   0.003222         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.936      0.575      0.745      0.446\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/29      3.05G    0.02136    0.01045   0.003174          6        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141       0.94      0.703       0.82      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/29      3.05G    0.02117    0.01045   0.003086         11        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.933        0.8      0.879       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/29      3.05G    0.02095    0.01037   0.003046          6        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.931       0.86      0.917       0.57\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/29      3.05G    0.02077    0.01027   0.002885          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.935      0.895      0.941      0.594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/29      3.05G    0.02049    0.01018   0.002894         17        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.941      0.917      0.955      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/29      3.05G    0.02026    0.01011   0.002813         15        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.946      0.929      0.965      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/29      3.05G    0.02011    0.01005   0.002706         12        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.949      0.939      0.971      0.634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/29      3.05G    0.01985   0.009941   0.002618          8        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141       0.95      0.948      0.975      0.641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/29      3.05G    0.01954   0.009869   0.002491          9        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.953      0.951      0.977      0.647\n",
      "\n",
      "30 epochs completed in 4.963 hours.\n",
      "Optimizer stripped from /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/ice_eye_mouth20_softBN_finetune_1e-3_fixed/weights/last.pt, 9.6MB\n",
      "Optimizer stripped from /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/ice_eye_mouth20_softBN_finetune_1e-3_fixed/weights/best.pt, 9.6MB\n",
      "\n",
      "Validating /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/ice_eye_mouth20_softBN_finetune_1e-3_fixed/weights/best.pt...\n",
      "Fusing layers... \n",
      "my_YOLOv5s_prune summary: 157 layers, 4655291 parameters, 0 gradients, 11.0 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   Exception in thread Thread-8 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 305, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 91, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "Exception in thread Thread-9 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 305, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 91, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "                 Class     Images  Instances          P          R      mAP50   Exception in thread Thread-10 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 305, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 91, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "Exception in thread Thread-11 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 305, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 91, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "Exception in thread Thread-12 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 305, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 91, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "Exception in thread Thread-13 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 305, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 91, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all      38704     104141      0.963      0.961      0.983      0.669\n",
      "             Leye_Open      38704      29887      0.983      0.984      0.992      0.727\n",
      "           Leye_Closed      38704       8067      0.946      0.939      0.973      0.574\n",
      "             Reye_Open      38704      28901      0.975      0.974      0.991      0.708\n",
      "           Reye_Closed      38704       7237      0.933      0.932      0.966      0.564\n",
      "            Mouth_Open      38704       8308      0.959      0.955      0.987      0.713\n",
      "          Mouth_Closed      38704      21741       0.98      0.981      0.988       0.73\n",
      "Results saved to \u001b[1m/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/ice_eye_mouth20_softBN_finetune_1e-3_fixed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "  --data /home/jovyan/lost+found/ice_sleep_detpj/data/ice_driver_ct.yaml \\\n",
    "  --cfg /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/models/my_yolov5s_prune.yaml \\\n",
    "  --weights /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/ice_eye_mouth20_pruned_finetune_33_40/weights/best.pt \\\n",
    "  --epochs 30 \\\n",
    "  --batch-size 16 \\\n",
    "  --img 640 \\\n",
    "  --project /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train \\\n",
    "  --name ice_eye_mouth20_softBN_finetune_1e-3_fixed \\\n",
    "  --exist-ok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cbc9569-9330-4b34-8677-62919b42f590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-02 21:58:35.471111: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-02 21:58:35.490419: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-02 21:58:35.490443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-02 21:58:35.490968: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-02 21:58:35.494122: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-02 21:58:35.858297: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/yolov5n.pt, cfg=/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/models/yolov5n.yaml, data=/home/jovyan/lost+found/ice_sleep_detpj/data/ice_driver_ct.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train, name=yolov5n_driver, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 446 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v7.0-0-g915bbf29 Python-3.11.9 torch-2.2.2+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12010MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train', view at http://localhost:6006/\n",
      "‚úÖ Loaded pruned model structure directly from checkpoint (.pt)\n",
      "layer                                     name  gradient   parameters                shape         mu      sigma\n",
      "    0                      model.0.conv.weight     False         1728        [16, 3, 6, 6]   -0.00121       0.13\n",
      "    1                        model.0.bn.weight     False           16                 [16]       2.39       1.48\n",
      "    2                          model.0.bn.bias     False           16                 [16]       1.02       3.18\n",
      "    3                      model.1.conv.weight     False         4608       [32, 16, 3, 3]  -0.000257      0.101\n",
      "    4                        model.1.bn.weight     False           32                 [32]       4.39       1.03\n",
      "    5                          model.1.bn.bias     False           32                 [32]      0.806       1.33\n",
      "    6                  model.2.cv1.conv.weight     False          512       [16, 32, 1, 1]     -0.015      0.141\n",
      "    7                    model.2.cv1.bn.weight     False           16                 [16]       1.58      0.839\n",
      "    8                      model.2.cv1.bn.bias     False           16                 [16]       1.02       1.21\n",
      "    9                  model.2.cv2.conv.weight     False          512       [16, 32, 1, 1]    -0.0124      0.147\n",
      "   10                    model.2.cv2.bn.weight     False           16                 [16]       2.16       1.17\n",
      "   11                      model.2.cv2.bn.bias     False           16                 [16]      0.873       1.42\n",
      "   12                  model.2.cv3.conv.weight     False         1024       [32, 32, 1, 1]    -0.0124       0.14\n",
      "   13                    model.2.cv3.bn.weight     False           32                 [32]       1.13      0.381\n",
      "   14                      model.2.cv3.bn.bias     False           32                 [32]      0.578      0.875\n",
      "   15              model.2.m.0.cv1.conv.weight     False          256       [16, 16, 1, 1]   -0.00112      0.138\n",
      "   16                model.2.m.0.cv1.bn.weight     False           16                 [16]       2.13       1.03\n",
      "   17                  model.2.m.0.cv1.bn.bias     False           16                 [16]      0.526       1.23\n",
      "   18              model.2.m.0.cv2.conv.weight     False         2304       [16, 16, 3, 3]   -0.00111     0.0788\n",
      "   19                model.2.m.0.cv2.bn.weight     False           16                 [16]        1.9      0.639\n",
      "   20                  model.2.m.0.cv2.bn.bias     False           16                 [16]      0.778       1.76\n",
      "   21                      model.3.conv.weight     False        18432       [64, 32, 3, 3]   -0.00248      0.052\n",
      "   22                        model.3.bn.weight     False           64                 [64]      0.866      0.209\n",
      "   23                          model.3.bn.bias     False           64                 [64]      0.173      0.819\n",
      "   24                  model.4.cv1.conv.weight     False         2048       [32, 64, 1, 1]   -0.00693     0.0831\n",
      "   25                    model.4.cv1.bn.weight     False           32                 [32]       0.42      0.168\n",
      "   26                      model.4.cv1.bn.bias     False           32                 [32]      0.175      0.579\n",
      "   27                  model.4.cv2.conv.weight     False         2048       [32, 64, 1, 1]   -0.00315     0.0899\n",
      "   28                    model.4.cv2.bn.weight     False           32                 [32]      0.964      0.237\n",
      "   29                      model.4.cv2.bn.bias     False           32                 [32]       0.43      0.729\n",
      "   30                  model.4.cv3.conv.weight     False         4096       [64, 64, 1, 1]   -0.00648      0.092\n",
      "   31                    model.4.cv3.bn.weight     False           64                 [64]      0.659      0.194\n",
      "   32                      model.4.cv3.bn.bias     False           64                 [64]     -0.219      0.732\n",
      "   33              model.4.m.0.cv1.conv.weight     False         1024       [32, 32, 1, 1]   -0.00933     0.0886\n",
      "   34                model.4.m.0.cv1.bn.weight     False           32                 [32]      0.795       0.23\n",
      "   35                  model.4.m.0.cv1.bn.bias     False           32                 [32]      0.315      0.839\n",
      "   36              model.4.m.0.cv2.conv.weight     False         9216       [32, 32, 3, 3]   -0.00167     0.0563\n",
      "   37                model.4.m.0.cv2.bn.weight     False           32                 [32]      0.696      0.158\n",
      "   38                  model.4.m.0.cv2.bn.bias     False           32                 [32]    -0.0626      0.813\n",
      "   39              model.4.m.1.cv1.conv.weight     False         1024       [32, 32, 1, 1]    -0.0132      0.097\n",
      "   40                model.4.m.1.cv1.bn.weight     False           32                 [32]      0.669      0.156\n",
      "   41                  model.4.m.1.cv1.bn.bias     False           32                 [32]      0.015      0.611\n",
      "   42              model.4.m.1.cv2.conv.weight     False         9216       [32, 32, 3, 3]   -0.00206     0.0522\n",
      "   43                model.4.m.1.cv2.bn.weight     False           32                 [32]      0.975      0.266\n",
      "   44                  model.4.m.1.cv2.bn.bias     False           32                 [32]      0.561      0.889\n",
      "   45                      model.5.conv.weight     False        73728      [128, 64, 3, 3]  -0.000673     0.0325\n",
      "   46                        model.5.bn.weight     False          128                [128]       0.75      0.211\n",
      "   47                          model.5.bn.bias     False          128                [128]     -0.204      0.628\n",
      "   48                  model.6.cv1.conv.weight     False         8192      [64, 128, 1, 1]   -0.00366      0.054\n",
      "   49                    model.6.cv1.bn.weight     False           64                 [64]      0.334      0.152\n",
      "   50                      model.6.cv1.bn.bias     False           64                 [64]     -0.223      0.521\n",
      "   51                  model.6.cv2.conv.weight     False         8192      [64, 128, 1, 1]   -0.00333     0.0568\n",
      "   52                    model.6.cv2.bn.weight     False           64                 [64]       1.08      0.173\n",
      "   53                      model.6.cv2.bn.bias     False           64                 [64]     0.0684      0.556\n",
      "   54                  model.6.cv3.conv.weight     False        16384     [128, 128, 1, 1]   -0.00452     0.0599\n",
      "   55                    model.6.cv3.bn.weight     False          128                [128]      0.782       0.22\n",
      "   56                      model.6.cv3.bn.bias     False          128                [128]     -0.432      0.852\n",
      "   57              model.6.m.0.cv1.conv.weight     False         4096       [64, 64, 1, 1]   -0.00965     0.0578\n",
      "   58                model.6.m.0.cv1.bn.weight     False           64                 [64]       1.01      0.235\n",
      "   59                  model.6.m.0.cv1.bn.bias     False           64                 [64]     -0.143      0.812\n",
      "   60              model.6.m.0.cv2.conv.weight     False        36864       [64, 64, 3, 3]   -0.00151     0.0332\n",
      "   61                model.6.m.0.cv2.bn.weight     False           64                 [64]      0.539      0.145\n",
      "   62                  model.6.m.0.cv2.bn.bias     False           64                 [64]     -0.411      0.518\n",
      "   63              model.6.m.1.cv1.conv.weight     False         4096       [64, 64, 1, 1]   -0.00967     0.0609\n",
      "   64                model.6.m.1.cv1.bn.weight     False           64                 [64]      0.864      0.174\n",
      "   65                  model.6.m.1.cv1.bn.bias     False           64                 [64]     -0.417      0.693\n",
      "   66              model.6.m.1.cv2.conv.weight     False        36864       [64, 64, 3, 3]   -0.00164     0.0323\n",
      "   67                model.6.m.1.cv2.bn.weight     False           64                 [64]      0.737      0.206\n",
      "   68                  model.6.m.1.cv2.bn.bias     False           64                 [64]    -0.0393      0.666\n",
      "   69              model.6.m.2.cv1.conv.weight     False         4096       [64, 64, 1, 1]    -0.0088     0.0601\n",
      "   70                model.6.m.2.cv1.bn.weight     False           64                 [64]      0.877      0.163\n",
      "   71                  model.6.m.2.cv1.bn.bias     False           64                 [64]     -0.515      0.679\n",
      "   72              model.6.m.2.cv2.conv.weight     False        36864       [64, 64, 3, 3]   -0.00148     0.0311\n",
      "   73                model.6.m.2.cv2.bn.weight     False           64                 [64]      0.993      0.221\n",
      "   74                  model.6.m.2.cv2.bn.bias     False           64                 [64]      0.252      0.596\n",
      "   75                      model.7.conv.weight     False       294912     [256, 128, 3, 3]  -0.000879       0.02\n",
      "   76                        model.7.bn.weight     False          256                [256]      0.943      0.151\n",
      "   77                          model.7.bn.bias     False          256                [256]     -0.637      0.392\n",
      "   78                  model.8.cv1.conv.weight     False        32768     [128, 256, 1, 1]   -0.00475     0.0385\n",
      "   79                    model.8.cv1.bn.weight     False          128                [128]      0.475      0.147\n",
      "   80                      model.8.cv1.bn.bias     False          128                [128]     -0.798      0.481\n",
      "   81                  model.8.cv2.conv.weight     False        32768     [128, 256, 1, 1]   -0.00307     0.0308\n",
      "   82                    model.8.cv2.bn.weight     False          128                [128]       1.16      0.124\n",
      "   83                      model.8.cv2.bn.bias     False          128                [128]     -0.528      0.259\n",
      "   84                  model.8.cv3.conv.weight     False        65536     [256, 256, 1, 1]   -0.00461     0.0342\n",
      "   85                    model.8.cv3.bn.weight     False          256                [256]       1.13      0.224\n",
      "   86                      model.8.cv3.bn.bias     False          256                [256]     -0.484      0.398\n",
      "   87              model.8.m.0.cv1.conv.weight     False        16384     [128, 128, 1, 1]   -0.00598      0.044\n",
      "   88                model.8.m.0.cv1.bn.weight     False          128                [128]       1.19      0.178\n",
      "   89                  model.8.m.0.cv1.bn.bias     False          128                [128]     -0.446      0.554\n",
      "   90              model.8.m.0.cv2.conv.weight     False       147456     [128, 128, 3, 3]   -0.00108     0.0219\n",
      "   91                model.8.m.0.cv2.bn.weight     False          128                [128]       1.33      0.277\n",
      "   92                  model.8.m.0.cv2.bn.bias     False          128                [128]     -0.222      0.526\n",
      "   93                  model.9.cv1.conv.weight     False        32768     [128, 256, 1, 1]   -0.00651     0.0401\n",
      "   94                    model.9.cv1.bn.weight     False          128                [128]      0.827      0.191\n",
      "   95                      model.9.cv1.bn.bias     False          128                [128]       1.18      0.453\n",
      "   96                  model.9.cv2.conv.weight     False       131072     [256, 512, 1, 1]    0.00027     0.0255\n",
      "   97                    model.9.cv2.bn.weight     False          256                [256]      0.879      0.177\n",
      "   98                      model.9.cv2.bn.bias     False          256                [256]     -0.995      0.527\n",
      "   99                     model.10.conv.weight     False        32768     [128, 256, 1, 1]   -0.00562     0.0374\n",
      "  100                       model.10.bn.weight     False          128                [128]      0.914      0.207\n",
      "  101                         model.10.bn.bias     False          128                [128]     -0.212       0.55\n",
      "  102                 model.13.cv1.conv.weight     False        16384      [64, 256, 1, 1]   -0.00244     0.0432\n",
      "  103                   model.13.cv1.bn.weight     False           64                 [64]      0.631      0.176\n",
      "  104                     model.13.cv1.bn.bias     False           64                 [64]     -0.235       0.78\n",
      "  105                 model.13.cv2.conv.weight     False        16384      [64, 256, 1, 1]   -0.00172     0.0383\n",
      "  106                   model.13.cv2.bn.weight     False           64                 [64]      0.694      0.156\n",
      "  107                     model.13.cv2.bn.bias     False           64                 [64]     0.0221       0.61\n",
      "  108                 model.13.cv3.conv.weight     False        16384     [128, 128, 1, 1]   -0.00518     0.0455\n",
      "  109                   model.13.cv3.bn.weight     False          128                [128]       0.72       0.18\n",
      "  110                     model.13.cv3.bn.bias     False          128                [128]     -0.354      0.671\n",
      "  111             model.13.m.0.cv1.conv.weight     False         4096       [64, 64, 1, 1]   -0.00524     0.0581\n",
      "  112               model.13.m.0.cv1.bn.weight     False           64                 [64]      0.667      0.166\n",
      "  113                 model.13.m.0.cv1.bn.bias     False           64                 [64]     -0.208      0.731\n",
      "  114             model.13.m.0.cv2.conv.weight     False        36864       [64, 64, 3, 3]   -0.00145      0.029\n",
      "  115               model.13.m.0.cv2.bn.weight     False           64                 [64]      0.686       0.19\n",
      "  116                 model.13.m.0.cv2.bn.bias     False           64                 [64]     0.0912      0.717\n",
      "  117                     model.14.conv.weight     False         8192      [64, 128, 1, 1]   -0.00281     0.0515\n",
      "  118                       model.14.bn.weight     False           64                 [64]      0.596      0.127\n",
      "  119                         model.14.bn.bias     False           64                 [64]      0.486      0.679\n",
      "  120                 model.17.cv1.conv.weight     False         4096      [32, 128, 1, 1]   -0.00163     0.0515\n",
      "  121                   model.17.cv1.bn.weight     False           32                 [32]      0.433      0.172\n",
      "  122                     model.17.cv1.bn.bias     False           32                 [32]     0.0128      0.842\n",
      "  123                 model.17.cv2.conv.weight     False         4096      [32, 128, 1, 1]  -0.000701     0.0389\n",
      "  124                   model.17.cv2.bn.weight     False           32                 [32]      0.648      0.385\n",
      "  125                     model.17.cv2.bn.bias     False           32                 [32]      0.734      0.553\n",
      "  126                 model.17.cv3.conv.weight     False         4096       [64, 64, 1, 1]   -0.00325     0.0578\n",
      "  127                   model.17.cv3.bn.weight     False           64                 [64]        2.2      0.712\n",
      "  128                     model.17.cv3.bn.bias     False           64                 [64]      0.791       1.32\n",
      "  129             model.17.m.0.cv1.conv.weight     False         1024       [32, 32, 1, 1]     -0.002     0.0722\n",
      "  130               model.17.m.0.cv1.bn.weight     False           32                 [32]      0.503      0.141\n",
      "  131                 model.17.m.0.cv1.bn.bias     False           32                 [32]      0.101      0.876\n",
      "  132             model.17.m.0.cv2.conv.weight     False         9216       [32, 32, 3, 3]   -0.00204     0.0345\n",
      "  133               model.17.m.0.cv2.bn.weight     False           32                 [32]      0.749      0.262\n",
      "  134                 model.17.m.0.cv2.bn.bias     False           32                 [32]      0.506      0.832\n",
      "  135                     model.18.conv.weight     False        36864       [64, 64, 3, 3]  -6.47e-05     0.0228\n",
      "  136                       model.18.bn.weight     False           64                 [64]      0.719      0.183\n",
      "  137                         model.18.bn.bias     False           64                 [64]    -0.0555      0.696\n",
      "  138                 model.20.cv1.conv.weight     False         8192      [64, 128, 1, 1]   -0.00091     0.0363\n",
      "  139                   model.20.cv1.bn.weight     False           64                 [64]      0.669      0.126\n",
      "  140                     model.20.cv1.bn.bias     False           64                 [64]    -0.0856      0.478\n",
      "  141                 model.20.cv2.conv.weight     False         8192      [64, 128, 1, 1]  -3.56e-05     0.0285\n",
      "  142                   model.20.cv2.bn.weight     False           64                 [64]      0.685      0.211\n",
      "  143                     model.20.cv2.bn.bias     False           64                 [64]      0.193      0.394\n",
      "  144                 model.20.cv3.conv.weight     False        16384     [128, 128, 1, 1]   -0.00294      0.033\n",
      "  145                   model.20.cv3.bn.weight     False          128                [128]       1.88      0.539\n",
      "  146                     model.20.cv3.bn.bias     False          128                [128]     0.0926      0.953\n",
      "  147             model.20.m.0.cv1.conv.weight     False         4096       [64, 64, 1, 1]   -0.00239     0.0445\n",
      "  148               model.20.m.0.cv1.bn.weight     False           64                 [64]      0.538      0.138\n",
      "  149                 model.20.m.0.cv1.bn.bias     False           64                 [64]     -0.353      0.575\n",
      "  150             model.20.m.0.cv2.conv.weight     False        36864       [64, 64, 3, 3]  -0.000818     0.0213\n",
      "  151               model.20.m.0.cv2.bn.weight     False           64                 [64]      0.847      0.275\n",
      "  152                 model.20.m.0.cv2.bn.bias     False           64                 [64]      0.194      0.664\n",
      "  153                     model.21.conv.weight     False       147456     [128, 128, 3, 3]  -0.000191     0.0122\n",
      "  154                       model.21.bn.weight     False          128                [128]      0.875      0.191\n",
      "  155                         model.21.bn.bias     False          128                [128]     -0.162      0.423\n",
      "  156                 model.23.cv1.conv.weight     False        32768     [128, 256, 1, 1]  -0.000827       0.02\n",
      "  157                   model.23.cv1.bn.weight     False          128                [128]      0.945      0.168\n",
      "  158                     model.23.cv1.bn.bias     False          128                [128]     -0.256       0.27\n",
      "  159                 model.23.cv2.conv.weight     False        32768     [128, 256, 1, 1]  -0.000739     0.0155\n",
      "  160                   model.23.cv2.bn.weight     False          128                [128]      0.922      0.175\n",
      "  161                     model.23.cv2.bn.bias     False          128                [128]     0.0576      0.298\n",
      "  162                 model.23.cv3.conv.weight     False        65536     [256, 256, 1, 1]   -0.00191      0.017\n",
      "  163                   model.23.cv3.bn.weight     False          256                [256]       1.58      0.488\n",
      "  164                     model.23.cv3.bn.bias     False          256                [256]    -0.0834      0.646\n",
      "  165             model.23.m.0.cv1.conv.weight     False        16384     [128, 128, 1, 1]   -0.00151     0.0239\n",
      "  166               model.23.m.0.cv1.bn.weight     False          128                [128]      0.858      0.188\n",
      "  167                 model.23.m.0.cv1.bn.bias     False          128                [128]      -0.34      0.422\n",
      "  168             model.23.m.0.cv2.conv.weight     False       147456     [128, 128, 3, 3]  -0.000558     0.0109\n",
      "  169               model.23.m.0.cv2.bn.weight     False          128                [128]        1.1      0.331\n",
      "  170                 model.23.m.0.cv2.bn.bias     False          128                [128]     -0.164      0.559\n",
      "  171                      model.24.m.0.weight     False        16320      [255, 64, 1, 1]    -0.0149      0.068\n",
      "  172                        model.24.m.0.bias     False          255                [255]      -5.18       1.52\n",
      "  173                      model.24.m.1.weight     False        32640     [255, 128, 1, 1]   -0.00928     0.0494\n",
      "  174                        model.24.m.1.bias     False          255                [255]      -5.69       1.54\n",
      "  175                      model.24.m.2.weight     False        65280     [255, 256, 1, 1]   -0.00436     0.0349\n",
      "  176                        model.24.m.2.bias     False          255                [255]      -6.18       1.63\n",
      "YOLOv5n summary: 270 layers, 1872157 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/jovyan/lost+found/ice_sleep_detpj/data/YOLO_dataset/labels\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/jovyan/lost+found/ice_sleep_detpj/data/YOLO_dataset/images/train/R_540_40_M_15_M0_G1_C0_11.jpg: ignoring corrupt image/label: negative label values [   -0.92917]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jovyan/lost+found/ice_sleep_detpj/data/YOLO_dataset/labels/v\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/jovyan/lost+found/ice_sleep_detpj/data/YOLO_dataset/labels/val.cache\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.80 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/29      1.97G    0.03534     0.0154   0.002799         20        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.625      0.771      0.715      0.438\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/29      2.16G    0.02967    0.01263   0.001789         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.851      0.862      0.912      0.578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/29      2.19G    0.02667    0.01204   0.001374         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.899      0.905      0.947      0.608\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/29       2.2G    0.02494     0.0117   0.001167          6        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.903      0.893       0.94      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/29       2.2G     0.0247    0.01157   0.001092          8        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.883       0.79      0.865      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/29       2.2G    0.02441    0.01145   0.001044          9        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.849      0.681      0.784      0.488\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/29       2.2G    0.02426    0.01136   0.001015         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.797      0.605      0.712      0.441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/29       2.2G    0.02404    0.01126  0.0009996          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.669      0.553      0.625      0.389\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/29       2.2G    0.02383    0.01122  0.0009816          9        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.648      0.433      0.513      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/29       2.2G    0.02363    0.01113  0.0009612         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.638      0.302      0.401      0.256\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/29       2.2G    0.02342    0.01108  0.0009423          3        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.171      0.463      0.301      0.195\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/29       2.2G    0.02327    0.01102  0.0009218         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.184      0.339      0.225      0.148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/29       2.2G    0.02308    0.01094  0.0009036         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.188      0.265      0.188      0.125\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/29       2.2G    0.02288    0.01091  0.0008923         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.187       0.22       0.17      0.113\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/29       2.2G    0.02276    0.01084   0.000875          8        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.186       0.21      0.166      0.111\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/29       2.2G    0.02259    0.01081  0.0008607          4        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.188      0.232      0.179      0.119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/29       2.2G    0.02243    0.01074  0.0008404         11        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.188       0.27      0.199      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/29       2.2G    0.02226    0.01067  0.0008253         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.186      0.328      0.235      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/29       2.2G    0.02212    0.01068  0.0008084         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.212      0.325      0.283      0.185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/29       2.2G    0.02189    0.01059  0.0007899         12        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.646      0.262      0.346      0.224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/29       2.2G    0.02178    0.01054  0.0007763         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.656      0.345      0.417      0.267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/29       2.2G    0.02159    0.01049  0.0007563          6        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141       0.71      0.425      0.499      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/29       2.2G    0.02144    0.01048  0.0007367         11        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.771      0.509      0.588      0.365\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/29       2.2G    0.02125    0.01042   0.000719          6        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.796      0.584      0.659      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/29       2.2G    0.02106    0.01032  0.0007005          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.826       0.64      0.714      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/29       2.2G    0.02079    0.01025  0.0006833         17        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.839      0.691      0.765      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/29       2.2G    0.02047    0.01019  0.0006691         15        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.852      0.741      0.811      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/29       2.2G    0.02028    0.01014  0.0006461         12        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.862      0.779      0.847      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/29       2.2G    0.02001    0.01003  0.0006255          8        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.871      0.811      0.876      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/29       2.2G    0.01969   0.009951  0.0006025          9        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.879      0.831      0.895      0.544\n",
      "\n",
      "30 epochs completed in 3.871 hours.\n",
      "Optimizer stripped from /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/weights/last.pt, 4.0MB\n",
      "Optimizer stripped from /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/weights/best.pt, 4.0MB\n",
      "\n",
      "Validating /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   Exception in thread Thread-12 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 304, in plot_images\n",
      "    cls = names[cls] if names else cls\n",
      "          ~~~~~^^^^^\n",
      "KeyError: 56\n",
      "                 Class     Images  Instances          P          R      mAP50   Exception in thread Thread-14 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 304, in plot_images\n",
      "    cls = names[cls] if names else cls\n",
      "          ~~~~~^^^^^\n",
      "KeyError: 56\n",
      "                 Class     Images  Instances          P          R      mAP50   Exception in thread Thread-16 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 304, in plot_images\n",
      "    cls = names[cls] if names else cls\n",
      "          ~~~~~^^^^^\n",
      "KeyError: 33\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\n",
      "                   all      38704     104141      0.903      0.893       0.94      0.609\n",
      "             Leye_Open      38704      29887      0.965       0.94      0.985      0.689\n",
      "           Leye_Closed      38704       8067      0.829      0.839      0.875      0.482\n",
      "             Reye_Open      38704      28901       0.95      0.946      0.982       0.66\n",
      "           Reye_Closed      38704       7237       0.81      0.839       0.87      0.466\n",
      "            Mouth_Open      38704       8308       0.97      0.814       0.95      0.663\n",
      "          Mouth_Closed      38704      21741      0.893      0.983      0.976      0.696\n",
      "Results saved to \u001b[1m/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "  --data /home/jovyan/lost+found/ice_sleep_detpj/data/ice_driver_ct.yaml \\\n",
    "  --cfg /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/models/yolov5n.yaml \\\n",
    "  --weights /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/yolov5n.pt \\\n",
    "  --epochs 30 \\\n",
    "  --batch-size 16 \\\n",
    "  --img 640 \\\n",
    "  --project /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train \\\n",
    "  --name yolov5n_driver \\\n",
    "  --hyp data/hyps/hyp.scratch-low.yaml \\\n",
    "  --exist-ok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2209cb5b-57dd-4518-820f-6ed0cad2a9bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/jovyan/lost+found/ice_sleep_detpj/data/ice_driver_ct.yaml, weights=['/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/weights/best.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/val, name=yolov5n_val, exist_ok=True, half=False, dnn=False\n",
      "YOLOv5 üöÄ v7.0-0-g915bbf29 Python-3.11.9 torch-2.2.2+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12010MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jovyan/lost+found/ice_sleep_detpj/data/YOLO_dataset/labels/v\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   Exception in thread Thread-4 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 304, in plot_images\n",
      "    cls = names[cls] if names else cls\n",
      "          ~~~~~^^^^^\n",
      "KeyError: 56\n",
      "Exception in thread Thread-6 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 304, in plot_images\n",
      "    cls = names[cls] if names else cls\n",
      "          ~~~~~^^^^^\n",
      "KeyError: 26\n",
      "                 Class     Images  Instances          P          R      mAP50   Exception in thread Thread-8 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/utils/plots.py\", line 304, in plot_images\n",
      "    cls = names[cls] if names else cls\n",
      "          ~~~~~^^^^^\n",
      "KeyError: 56\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Saved PR_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/val/yolov5n_val/PR_curve.npy\n",
      "Saved F1_curve.npy ‚Üí /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/val/yolov5n_val/F1_curve.npy\n",
      "‚úÖ Saved P/R numpy arrays to /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/val/yolov5n_val\n",
      "                   all      38704     104141      0.903      0.893      0.939      0.609\n",
      "             Leye_Open      38704      29887      0.965       0.94      0.985      0.689\n",
      "           Leye_Closed      38704       8067      0.829      0.839      0.875      0.482\n",
      "             Reye_Open      38704      28901       0.95      0.945      0.981       0.66\n",
      "           Reye_Closed      38704       7237      0.811      0.839       0.87      0.466\n",
      "            Mouth_Open      38704       8308       0.97      0.813       0.95      0.664\n",
      "          Mouth_Closed      38704      21741      0.893      0.982      0.976      0.696\n",
      "Speed: 0.1ms pre-process, 0.5ms inference, 0.4ms NMS per image at shape (16, 3, 640, 640)\n",
      "\n",
      "Evaluating pycocotools mAP... saving /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/val/yolov5n_val/best_predictions.json...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirement \"pycocotools\" not found, attempting AutoUpdate...\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from pycocotools) (1.26.4)\n",
      "Downloading pycocotools-2.0.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (477 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m477.3/477.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pycocotools\n",
      "Successfully installed pycocotools-2.0.10\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per ['pycocotools']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "loading annotations into memory...\n",
      "pycocotools unable to run: [Errno 2] No such file or directory: '/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/annotations/instances_val2017.json'\n",
      "Results saved to \u001b[1m/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/val/yolov5n_val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python val.py \\\n",
    "  --weights /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/weights/best.pt \\\n",
    "  --data /home/jovyan/lost+found/ice_sleep_detpj/data/ice_driver_ct.yaml \\\n",
    "  --img 640 \\\n",
    "  --batch-size 16 \\\n",
    "  --task val \\\n",
    "  --project /home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/val \\\n",
    "  --name yolov5n_val \\\n",
    "  --save-json \\\n",
    "  --exist-ok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "704ec460-4e8b-4c67-a9d9-75d906feb032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFLOPs: 2.23, Params: 1.87M\n"
     ]
    }
   ],
   "source": [
    "from models.common import DetectMultiBackend\n",
    "from thop import profile\n",
    "import torch\n",
    "\n",
    "# ‚úÖ ÏàòÏ†ïÎêú ÏΩîÎìú\n",
    "device = torch.device('cpu')\n",
    "model = DetectMultiBackend(\n",
    "    '/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/runs/train/yolov5n_driver/weights/best.pt',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 640, 640).to(device)\n",
    "flops, params = profile(model.model, inputs=(dummy_input,), verbose=False)\n",
    "print(f\"GFLOPs: {flops/1e9:.2f}, Params: {params/1e6:.2f}M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc9c6b0f-999c-403c-a632-707c97007a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting thop\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from thop) (2.2.2+cu121)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->thop) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->thop) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->thop) (1.12.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->thop) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->thop) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->thop) (2024.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->thop) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->thop) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->thop) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch->thop) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->thop) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->thop) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->thop) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->thop) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->thop) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.11/site-packages (from torch->thop) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->thop) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.11/site-packages (from torch->thop) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->thop) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->thop) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->thop) (1.3.0)\n",
      "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: thop\n",
      "Successfully installed thop-0.1.1.post2209072238\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44faac2b-7a26-4b1c-823a-0cd6239bf995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n",
      "\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     16240  models.common.Conv                      [32, 56, 3, 2]                \n",
      "  2                -1  1     14448  models.common.C3                        [56, 56, 1]                   \n",
      "  3                -1  1     52624  models.common.Conv                      [56, 104, 3, 2]               \n",
      "  4                -1  2     76544  models.common.C3                        [104, 104, 2]                 \n",
      "  5                -1  1    195104  models.common.Conv                      [104, 208, 3, 2]              \n",
      "  6                -1  3    413088  models.common.C3                        [208, 208, 3]                 \n",
      "  7                -1  1    779584  models.common.Conv                      [208, 416, 3, 2]              \n",
      "  8                -1  1    781248  models.common.C3                        [416, 416, 1]                 \n",
      "  9                -1  1    433888  models.common.SPPF                      [416, 416, 5]                 \n",
      " 10                -1  1     86944  models.common.Conv                      [416, 208, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    239200  models.common.C3                        [416, 208, 1, False]          \n",
      " 14                -1  1     21840  models.common.Conv                      [208, 104, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     60112  models.common.C3                        [208, 104, 1, False]          \n",
      " 18                -1  1     97552  models.common.Conv                      [104, 104, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    195936  models.common.C3                        [208, 208, 1, False]          \n",
      " 21                -1  1    389792  models.common.Conv                      [208, 208, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1    781248  models.common.C3                        [416, 416, 1, False]          \n",
      " 24      [17, 20, 23]  1     24123  models.yolo.Detect                      [6, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [104, 208, 416]]\n",
      "my_YOLOv5s_prune summary: 214 layers, 4663035 parameters, 4663035 gradients, 11.2 GFLOPs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_upsample() for <class 'torch.nn.modules.upsampling.Upsample'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_upsample() for <class 'torch.nn.modules.upsampling.Upsample'>.\n",
      "YOLOv5s (Í∏∞Î≥∏):\n",
      "  Params: 7.24M,  GFLOPs: 8.31\n",
      "\n",
      "YAML Í≤ΩÎüâÌôî Î™®Îç∏:\n",
      "  Params: 4.66M,  GFLOPs: 5.60\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from thop import profile\n",
    "from models.yolo import Model  # YOLOv5 Íµ¨Ï°∞ Ï†ïÏùò ÌååÏùº (yolov5/models/yolo.py)\n",
    "from pathlib import Path\n",
    "\n",
    "# =====================================================\n",
    "# 1Ô∏è‚É£ Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
    "# =====================================================\n",
    "yaml_base = Path(\"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/models/yolov5s.yaml\")  # Í∏∞Î≥∏ YOLOv5s Íµ¨Ï°∞\n",
    "yaml_light = Path(\"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/models/my_yolov5s_prune.yaml\")  # YAML ÏàòÏ†ï ÌõÑ Íµ¨Ï°∞\n",
    "\n",
    "# =====================================================\n",
    "# 2Ô∏è‚É£ Î™®Îç∏ Î°úÎìú\n",
    "# =====================================================\n",
    "model_base = Model(cfg=yaml_base)   # Í∏∞Î≥∏ YOLOv5s\n",
    "model_light = Model(cfg=yaml_light) # YAML Í∏∞Î∞ò Í≤ΩÎüâÌôî YOLOv5s\n",
    "\n",
    "# =====================================================\n",
    "# 3Ô∏è‚É£ ÏûÖÎ†• ÏÉòÌîå ÏÑ§Ï†ï (640x640)\n",
    "# =====================================================\n",
    "x = torch.randn(1, 3, 640, 640)\n",
    "\n",
    "# =====================================================\n",
    "# 4Ô∏è‚É£ GFLOPs / Params Í≥ÑÏÇ∞\n",
    "# =====================================================\n",
    "macs_base, params_base = profile(model_base, inputs=(x,))\n",
    "macs_light, params_light = profile(model_light, inputs=(x,))\n",
    "\n",
    "print(\"YOLOv5s (Í∏∞Î≥∏):\")\n",
    "print(f\"  Params: {params_base/1e6:.2f}M,  GFLOPs: {macs_base/1e9:.2f}\")\n",
    "\n",
    "print(\"\\nYAML Í≤ΩÎüâÌôî Î™®Îç∏:\")\n",
    "print(f\"  Params: {params_light/1e6:.2f}M,  GFLOPs: {macs_light/1e9:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbdedc4e-d515-4f43-8313-44c89679dde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     29667  models.yolo.Detect                      [6, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "YOLOv5s summary: 214 layers, 7035811 parameters, 7035811 gradients, 16.0 GFLOPs\n",
      "\n",
      "YOLOv5s summary: 214 layers, 7035811 parameters, 7035811 gradients, 16.0 GFLOPs\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     16240  models.common.Conv                      [32, 56, 3, 2]                \n",
      "  2                -1  1     14448  models.common.C3                        [56, 56, 1]                   \n",
      "  3                -1  1     52624  models.common.Conv                      [56, 104, 3, 2]               \n",
      "  4                -1  2     76544  models.common.C3                        [104, 104, 2]                 \n",
      "  5                -1  1    195104  models.common.Conv                      [104, 208, 3, 2]              \n",
      "  6                -1  3    413088  models.common.C3                        [208, 208, 3]                 \n",
      "  7                -1  1    779584  models.common.Conv                      [208, 416, 3, 2]              \n",
      "  8                -1  1    781248  models.common.C3                        [416, 416, 1]                 \n",
      "  9                -1  1    433888  models.common.SPPF                      [416, 416, 5]                 \n",
      " 10                -1  1     86944  models.common.Conv                      [416, 208, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    239200  models.common.C3                        [416, 208, 1, False]          \n",
      " 14                -1  1     21840  models.common.Conv                      [208, 104, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     60112  models.common.C3                        [208, 104, 1, False]          \n",
      " 18                -1  1     97552  models.common.Conv                      [104, 104, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    195936  models.common.C3                        [208, 208, 1, False]          \n",
      " 21                -1  1    389792  models.common.Conv                      [208, 208, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1    781248  models.common.C3                        [416, 416, 1, False]          \n",
      " 24      [17, 20, 23]  1     24123  models.yolo.Detect                      [6, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [104, 208, 416]]\n",
      "my_YOLOv5s_prune summary: 214 layers, 4663035 parameters, 4663035 gradients, 11.2 GFLOPs\n",
      "\n",
      "my_YOLOv5s_prune summary: 214 layers, 4663035 parameters, 4663035 gradients, 11.2 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.yolo import Model\n",
    "from pathlib import Path\n",
    "import sys, io\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# ================================\n",
    "# üß± 1Ô∏è‚É£ Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
    "# ================================\n",
    "log_dir = Path(\"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/models/logs\")\n",
    "fig_dir = Path(\"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/models/figures\")\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ================================\n",
    "# ‚öôÔ∏è 2Ô∏è‚É£ YOLO Î™®Îç∏ ÏöîÏïΩ Ï†ÄÏû• Ìï®Ïàò\n",
    "# ================================\n",
    "def save_model_info(cfg_path, save_path):\n",
    "    model = Model(cfg=cfg_path)\n",
    "    buffer = io.StringIO()\n",
    "    sys.stdout = buffer\n",
    "    model.info(verbose=True)\n",
    "    sys.stdout = sys.__stdout__\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(buffer.getvalue())\n",
    "    print(f\"‚úÖ Saved model summary ‚Üí {save_path}\")\n",
    "\n",
    "# ================================\n",
    "# üìò 3Ô∏è‚É£ Í∏∞Î≥∏/Í≤ΩÎüâÌôî Î™®Îç∏ info Ï†ÄÏû•\n",
    "# ================================\n",
    "cfg_base = \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/models/yolov5s.yaml\"           # Í∏∞Î≥∏ Íµ¨Ï°∞\n",
    "cfg_light = \"/home/jovyan/lost+found/ice_sleep_detpj/yolov5_v7/models/my_yolov5s_prune.yaml\"    # YAML ÏàòÏ†ï Íµ¨Ï°∞\n",
    "\n",
    "save_model_info(cfg_base, log_dir / \"yolov5s_summary.txt\")\n",
    "save_model_info(cfg_light, log_dir / \"yolov5s_light_summary.txt\")\n",
    "\n",
    "# ================================\n",
    "# üé® 4Ô∏è‚É£ Íµ¨Ï°∞ ÎπÑÍµê Îã§Ïù¥Ïñ¥Í∑∏Îû® ÏÉùÏÑ±\n",
    "# ================================\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "blocks = [\"Input\", \"Backbone (C3)\", \"Neck (SPPF)\", \"Detect Head\"]\n",
    "x_pos = [0, 1.5, 3, 4.5]\n",
    "\n",
    "# ---- Baseline ----\n",
    "for x, name in zip(x_pos, blocks):\n",
    "    ax.add_patch(Rectangle((x, 1.4), 1, 0.5, color=\"#3C78D8\", ec=\"black\", lw=1.5))\n",
    "    ax.text(x + 0.5, 1.65, name, ha=\"center\", va=\"center\", color=\"white\", fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "# ---- YAML Light ----\n",
    "for x, name in zip(x_pos, blocks):\n",
    "    ax.add_patch(Rectangle((x, 0.4), 1, 0.5, color=\"#6AA84F\", ec=\"black\", lw=1.5))\n",
    "    ax.text(x + 0.5, 0.65, name, ha=\"center\", va=\"center\", color=\"white\", fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "# ---- Ïó∞Í≤∞ ÌôîÏÇ¥Ìëú ----\n",
    "for i in range(len(blocks) - 1):\n",
    "    ax.arrow(x_pos[i] + 1, 1.65, 0.3, 0, head_width=0.08, head_length=0.15, fc='black', ec='black')\n",
    "    ax.arrow(x_pos[i] + 1, 0.65, 0.3, 0, head_width=0.08, head_length=0.15, fc='black', ec='black')\n",
    "\n",
    "# ---- ÎùºÎ≤® ----\n",
    "ax.text(2.2, 2.05, \"YOLOv5s (Baseline)\", ha=\"center\", fontsize=12, fontweight=\"bold\", color=\"#3C78D8\")\n",
    "ax.text(2.2, 0.05, \"YAML Í≤ΩÎüâÌôî Î™®Îç∏\", ha=\"center\", fontsize=12, fontweight=\"bold\", color=\"#6AA84F\")\n",
    "\n",
    "ax.set_xlim(-0.5, 5.5)\n",
    "ax.set_ylim(-0.2, 2.3)\n",
    "ax.axis(\"off\")\n",
    "\n",
    "save_path = fig_dir / \"structure_compare.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(f\"‚úÖ Saved structure comparison diagram ‚Üí {save_path}\")\n",
    "print(\"\\nüéØ Î™®Îì† Í≤∞Í≥º ÏÉùÏÑ± ÏôÑÎ£å!\")\n",
    "print(f\"- {log_dir}/yolov5s_summary.txt\")\n",
    "print(f\"- {log_dir}/yolov5s_light_summary.txt\")\n",
    "print(f\"- {fig_dir}/structure_compare.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86fee64-32a6-40fa-8b79-e22593fdede6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
